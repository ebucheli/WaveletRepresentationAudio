{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Transform Concatenate into 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we concatenate the bands of the wt into a 1D vector, we feed this 1D input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleSpeechCommands import get_word_dict, read_list, load_data\n",
    "from SimpleSpeechCommands import append_examples,partition_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_label,label_to_word = get_word_dict()\n",
    "path_dataset = '/home/edoardobucheli/TFSpeechCommands/train/audio'\n",
    "#path_dataset = '/Users/edoardobucheli/Documents/MCC/Tesis/Kaggle_SpeechCommands/train/audio'\n",
    "sr = 16000\n",
    "file_length = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = read_list(path_dataset,'training_files.txt')\n",
    "validation_files = read_list(path_dataset,'validation_files.txt')\n",
    "testing_files = read_list(path_dataset,'testing_files.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25112/25112 [00:08<00:00, 3080.25it/s]\n",
      "100%|██████████| 3424/3424 [00:01<00:00, 3062.72it/s]\n",
      "100%|██████████| 3430/3430 [00:01<00:00, 3059.48it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = load_data(training_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_val,y_val = load_data(validation_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_test,y_test = load_data(testing_files,sr,file_length,path_dataset,word_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgrounds = partition_directory(path_dataset,'_background_noise_',sr,file_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = append_examples(x_train,y_train,backgrounds[:300],11)\n",
    "x_val,y_val = append_examples(x_val,y_val,backgrounds[300:320],11)\n",
    "x_test,y_test = append_examples(x_test,y_test,backgrounds[320:],11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 16000)\n",
      "(25412,)\n",
      "(3444, 16000)\n",
      "(3444,)\n",
      "(3508, 16000)\n",
      "(3508,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import wavedec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wavedec(x_train[0],'db4',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = [f for l in test for f in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "16070\n"
     ]
    }
   ],
   "source": [
    "levels = len(test)\n",
    "print(levels)\n",
    "res = len(new_test)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25412/25412 [00:11<00:00, 2264.13it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = np.zeros((len(x_train),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_train)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    #this_plain = []\n",
    "    for j in range(levels):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_train_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3444/3444 [00:01<00:00, 2265.17it/s]\n"
     ]
    }
   ],
   "source": [
    "x_val_2 = np.zeros((len(x_val),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_val)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    for j in range(levels):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_val_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_length = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities import make_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, _ = x_train_2.shape\n",
    "N_val, _ = x_val_2.shape\n",
    "#N_test, _ = x_test_2.shape\n",
    "\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = make_oh(y_train)\n",
    "y_val_oh = make_oh(y_val)\n",
    "#y_test_oh = make_oh(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 16070)\n",
      "(25412, 12)\n",
      "(3444, 16070)\n",
      "(3444, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_2.shape)\n",
    "print(y_train_oh.shape)\n",
    "print(x_val_2.shape)\n",
    "print(y_val_oh.shape)\n",
    "#print(x_test.shape)\n",
    "#print(y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, CuDNNGRU\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNN1_1D(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16070)             0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 16070, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 16062, 16)         160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2007, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1999, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 249, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 241, 32)           9248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 40, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 109,484\n",
      "Trainable params: 109,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "crnn1D = CRNN1_1D(input_shape, n_classes)\n",
    "crnn1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn1D.compile(optimizer = Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 13s 524us/step - loss: 2.2301 - acc: 0.2690 - val_loss: 1.8366 - val_acc: 0.3383\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 11s 442us/step - loss: 1.6984 - acc: 0.4074 - val_loss: 1.2441 - val_acc: 0.5624\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 11s 442us/step - loss: 1.3156 - acc: 0.5351 - val_loss: 1.0558 - val_acc: 0.6373\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 12s 455us/step - loss: 1.1048 - acc: 0.6140 - val_loss: 0.9139 - val_acc: 0.6919\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.9757 - acc: 0.6675 - val_loss: 0.7585 - val_acc: 0.7483\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.8666 - acc: 0.7041 - val_loss: 0.7017 - val_acc: 0.7636\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.7977 - acc: 0.7330 - val_loss: 0.6350 - val_acc: 0.7877\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 11s 447us/step - loss: 0.7383 - acc: 0.7517 - val_loss: 0.6021 - val_acc: 0.7973\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 12s 455us/step - loss: 0.6907 - acc: 0.7676 - val_loss: 0.5884 - val_acc: 0.8028\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 11s 448us/step - loss: 0.6449 - acc: 0.7810 - val_loss: 0.5626 - val_acc: 0.8150\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 12s 455us/step - loss: 0.6253 - acc: 0.7930 - val_loss: 0.5634 - val_acc: 0.8118\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 12s 458us/step - loss: 0.5959 - acc: 0.8017 - val_loss: 0.5646 - val_acc: 0.8133\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.5804 - acc: 0.8061 - val_loss: 0.5210 - val_acc: 0.8249\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 12s 453us/step - loss: 0.5509 - acc: 0.8182 - val_loss: 0.4923 - val_acc: 0.8328\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 12s 467us/step - loss: 0.5403 - acc: 0.8213 - val_loss: 0.4863 - val_acc: 0.8397\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 12s 470us/step - loss: 0.5089 - acc: 0.8311 - val_loss: 0.4831 - val_acc: 0.8449\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 12s 454us/step - loss: 0.5038 - acc: 0.8319 - val_loss: 0.4706 - val_acc: 0.8458\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 12s 461us/step - loss: 0.4866 - acc: 0.8383 - val_loss: 0.4795 - val_acc: 0.8449\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 12s 455us/step - loss: 0.4681 - acc: 0.8421 - val_loss: 0.4649 - val_acc: 0.8487\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 11s 441us/step - loss: 0.4526 - acc: 0.8467 - val_loss: 0.4682 - val_acc: 0.8493\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 11s 442us/step - loss: 0.4430 - acc: 0.8514 - val_loss: 0.4722 - val_acc: 0.8531\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 11s 439us/step - loss: 0.4297 - acc: 0.8529 - val_loss: 0.4588 - val_acc: 0.8583\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 11s 446us/step - loss: 0.4247 - acc: 0.8575 - val_loss: 0.4788 - val_acc: 0.8554\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 11s 440us/step - loss: 0.4149 - acc: 0.8603 - val_loss: 0.4662 - val_acc: 0.8539\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 11s 443us/step - loss: 0.4104 - acc: 0.8629 - val_loss: 0.4586 - val_acc: 0.8557\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 11s 441us/step - loss: 0.4060 - acc: 0.8623 - val_loss: 0.4539 - val_acc: 0.8583\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 11s 443us/step - loss: 0.3818 - acc: 0.8703 - val_loss: 0.4455 - val_acc: 0.8551\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 11s 441us/step - loss: 0.3768 - acc: 0.8731 - val_loss: 0.4549 - val_acc: 0.8583\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 11s 441us/step - loss: 0.3720 - acc: 0.8742 - val_loss: 0.4520 - val_acc: 0.8606\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 11s 442us/step - loss: 0.3649 - acc: 0.8779 - val_loss: 0.4807 - val_acc: 0.8574\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 12s 459us/step - loss: 0.3505 - acc: 0.8819 - val_loss: 0.4517 - val_acc: 0.8667\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 12s 475us/step - loss: 0.3447 - acc: 0.8838 - val_loss: 0.4572 - val_acc: 0.8659\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 12s 467us/step - loss: 0.3409 - acc: 0.8848 - val_loss: 0.4444 - val_acc: 0.8635\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 12s 455us/step - loss: 0.3328 - acc: 0.8875 - val_loss: 0.4561 - val_acc: 0.8630\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 12s 467us/step - loss: 0.3268 - acc: 0.8915 - val_loss: 0.4605 - val_acc: 0.8664\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 12s 457us/step - loss: 0.3187 - acc: 0.8926 - val_loss: 0.4668 - val_acc: 0.8664\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 11s 446us/step - loss: 0.3219 - acc: 0.8905 - val_loss: 0.4654 - val_acc: 0.8693\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.3144 - acc: 0.8942 - val_loss: 0.4425 - val_acc: 0.8725\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.3002 - acc: 0.8966 - val_loss: 0.4490 - val_acc: 0.8722\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.2973 - acc: 0.8995 - val_loss: 0.4628 - val_acc: 0.8728\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.2894 - acc: 0.9011 - val_loss: 0.4598 - val_acc: 0.8725\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.2794 - acc: 0.9038 - val_loss: 0.4505 - val_acc: 0.8737\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.2761 - acc: 0.9056 - val_loss: 0.4841 - val_acc: 0.8685\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.4838 - val_acc: 0.8728\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.2665 - acc: 0.9082 - val_loss: 0.4670 - val_acc: 0.8734\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 11s 441us/step - loss: 0.2653 - acc: 0.9070 - val_loss: 0.4806 - val_acc: 0.8728\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.2597 - acc: 0.9112 - val_loss: 0.4859 - val_acc: 0.8711\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 11s 445us/step - loss: 0.2550 - acc: 0.9148 - val_loss: 0.4841 - val_acc: 0.8720\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.2583 - acc: 0.9109 - val_loss: 0.4955 - val_acc: 0.8728\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 11s 444us/step - loss: 0.2527 - acc: 0.9124 - val_loss: 0.4718 - val_acc: 0.8795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fcc4f4f98>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn1D.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh],\n",
    "           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dropout, Activation\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, Dense, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_v1(input_shape,n_classes):\n",
    "\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(16)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = GlobalMaxPool1D()(X)\n",
    "\n",
    "    X = Dense(64,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "\n",
    "    X = Dense(n_classes,activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input,outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 16070)             0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 16070, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16062, 16)         160       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16054, 16)         2320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1003, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1003, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1001, 32)          1568      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 999, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 249, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 249, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 247, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 245, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 59, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 57, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 261,372\n",
      "Trainable params: 261,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1d = conv1d_v1(input_shape,n_classes)\n",
    "cnn1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1d.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 24s 927us/step - loss: 2.2717 - acc: 0.2637 - val_loss: 1.9901 - val_acc: 0.2959\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 21s 835us/step - loss: 1.6502 - acc: 0.4169 - val_loss: 1.3759 - val_acc: 0.5264\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 22s 846us/step - loss: 1.1364 - acc: 0.6103 - val_loss: 0.9183 - val_acc: 0.6963\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 22s 848us/step - loss: 0.8813 - acc: 0.7019 - val_loss: 0.7977 - val_acc: 0.7471\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 22s 846us/step - loss: 0.7499 - acc: 0.7499 - val_loss: 0.6473 - val_acc: 0.7828\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 21s 846us/step - loss: 0.6646 - acc: 0.7791 - val_loss: 0.6346 - val_acc: 0.7901\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 21s 846us/step - loss: 0.5890 - acc: 0.8028 - val_loss: 0.6147 - val_acc: 0.7970\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.5407 - acc: 0.8197 - val_loss: 0.5355 - val_acc: 0.8220\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 22s 852us/step - loss: 0.5053 - acc: 0.8326 - val_loss: 0.4867 - val_acc: 0.8426\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 22s 847us/step - loss: 0.4831 - acc: 0.8368 - val_loss: 0.5103 - val_acc: 0.8267\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 22s 850us/step - loss: 0.4513 - acc: 0.8486 - val_loss: 0.4735 - val_acc: 0.8432\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.4278 - acc: 0.8581 - val_loss: 0.4696 - val_acc: 0.8513\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 21s 845us/step - loss: 0.4021 - acc: 0.8657 - val_loss: 0.4779 - val_acc: 0.8418\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 21s 843us/step - loss: 0.3822 - acc: 0.8720 - val_loss: 0.4156 - val_acc: 0.8638\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 21s 845us/step - loss: 0.3751 - acc: 0.8734 - val_loss: 0.4257 - val_acc: 0.8574\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 22s 848us/step - loss: 0.3653 - acc: 0.8776 - val_loss: 0.4303 - val_acc: 0.8580\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 22s 849us/step - loss: 0.3486 - acc: 0.8820 - val_loss: 0.4495 - val_acc: 0.8531\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 21s 843us/step - loss: 0.3288 - acc: 0.8878 - val_loss: 0.4095 - val_acc: 0.8624\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 21s 845us/step - loss: 0.3196 - acc: 0.8919 - val_loss: 0.4139 - val_acc: 0.8621\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 21s 846us/step - loss: 0.3154 - acc: 0.8926 - val_loss: 0.3976 - val_acc: 0.8673\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 21s 845us/step - loss: 0.3003 - acc: 0.8986 - val_loss: 0.3765 - val_acc: 0.8766\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 22s 848us/step - loss: 0.2879 - acc: 0.9032 - val_loss: 0.3983 - val_acc: 0.8685\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 27s 1ms/step - loss: 0.2753 - acc: 0.9045 - val_loss: 0.3730 - val_acc: 0.8807\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 26s 1ms/step - loss: 0.2779 - acc: 0.9076 - val_loss: 0.4066 - val_acc: 0.8708\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 25s 988us/step - loss: 0.2613 - acc: 0.9084 - val_loss: 0.4035 - val_acc: 0.8693\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 25s 985us/step - loss: 0.2573 - acc: 0.9115 - val_loss: 0.4291 - val_acc: 0.8641\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 25s 986us/step - loss: 0.2563 - acc: 0.9104 - val_loss: 0.4511 - val_acc: 0.8592\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 25s 984us/step - loss: 0.2456 - acc: 0.9161 - val_loss: 0.3858 - val_acc: 0.8749\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 25s 984us/step - loss: 0.2315 - acc: 0.9207 - val_loss: 0.3932 - val_acc: 0.8815\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 25s 985us/step - loss: 0.2336 - acc: 0.9206 - val_loss: 0.3868 - val_acc: 0.8821\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 25s 987us/step - loss: 0.2235 - acc: 0.9228 - val_loss: 0.3811 - val_acc: 0.8766\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 25s 987us/step - loss: 0.2186 - acc: 0.9237 - val_loss: 0.3883 - val_acc: 0.8792\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 25s 969us/step - loss: 0.2119 - acc: 0.9264 - val_loss: 0.4259 - val_acc: 0.8685\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 22s 876us/step - loss: 0.1977 - acc: 0.9318 - val_loss: 0.3915 - val_acc: 0.8810\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 22s 866us/step - loss: 0.2027 - acc: 0.9304 - val_loss: 0.3991 - val_acc: 0.8801\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 22s 885us/step - loss: 0.1941 - acc: 0.9327 - val_loss: 0.4060 - val_acc: 0.8824\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 25s 996us/step - loss: 0.1866 - acc: 0.9354 - val_loss: 0.3881 - val_acc: 0.8801\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 22s 864us/step - loss: 0.1899 - acc: 0.9333 - val_loss: 0.4326 - val_acc: 0.8720\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1838 - acc: 0.9352 - val_loss: 0.4123 - val_acc: 0.8763\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1703 - acc: 0.9407 - val_loss: 0.4095 - val_acc: 0.8833\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 22s 847us/step - loss: 0.1669 - acc: 0.9420 - val_loss: 0.4268 - val_acc: 0.8786 loss: 0.1680 - acc: 0\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 21s 842us/step - loss: 0.1672 - acc: 0.9408 - val_loss: 0.4394 - val_acc: 0.8798\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 21s 846us/step - loss: 0.1618 - acc: 0.9427 - val_loss: 0.4077 - val_acc: 0.8815\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1601 - acc: 0.9425 - val_loss: 0.4026 - val_acc: 0.8859\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1599 - acc: 0.9453 - val_loss: 0.4371 - val_acc: 0.8775\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 21s 841us/step - loss: 0.1505 - acc: 0.9463 - val_loss: 0.4445 - val_acc: 0.8749\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1516 - acc: 0.9493 - val_loss: 0.4427 - val_acc: 0.8798\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 21s 844us/step - loss: 0.1409 - acc: 0.9496 - val_loss: 0.4528 - val_acc: 0.8798\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 21s 832us/step - loss: 0.1472 - acc: 0.9475 - val_loss: 0.4265 - val_acc: 0.8798\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 21s 842us/step - loss: 0.1481 - acc: 0.9473 - val_loss: 0.4454 - val_acc: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fcb355908>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1d.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, Dot, Softmax\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, Permute\n",
    "from tensorflow.keras.layers import Bidirectional, CuDNNLSTM, MaxPool1D\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import squeeze,stack, expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttRNNSpeechModelWave(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    #X = Lambda(lambda q: squeeze(q, -1), name='squeeze_last_dim') (X)\n",
    "\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    xFirst = Lambda(lambda q: q[:,16]) (X)\n",
    "    query = Dense(128) (xFirst)\n",
    "    query = Dropout(0.5)(query)\n",
    "\n",
    "    attScores = Dot(axes=[1,2])([query, X])\n",
    "    attScores = Softmax(name='attSoftmax')(attScores)\n",
    "\n",
    "    attVector = Dot(axes=[1,1])([attScores, X])\n",
    "\n",
    "    X = Dense(64, activation = 'relu')(attVector)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(32)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax', name='output')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16070)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "expand_dims (Lambda)            (None, 16070, 1)     0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16062, 16)    160         expand_dims[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 2007, 16)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1999, 32)     4640        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 249, 32)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 241, 32)      9248        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 40, 32)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 40, 128)      50176       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 40, 128)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 40, 128)      99328       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 40, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 40)           0           dropout_8[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attSoftmax (Softmax)            (None, 40)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 128)          0           attSoftmax[0][0]                 \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 12)           396         dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 190,796\n",
      "Trainable params: 190,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attRNN = AttRNNSpeechModelWave(input_shape,n_classes)\n",
    "attRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attRNN.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 14s 570us/step - loss: 2.3607 - acc: 0.2400 - val_loss: 2.1689 - val_acc: 0.2715\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 2.1343 - acc: 0.2869 - val_loss: 1.8838 - val_acc: 0.3461\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 1.9357 - acc: 0.3280 - val_loss: 1.7259 - val_acc: 0.3882\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 1.7668 - acc: 0.3771 - val_loss: 1.4992 - val_acc: 0.4730\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 1.6064 - acc: 0.4340 - val_loss: 1.4505 - val_acc: 0.4884\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 1.4674 - acc: 0.4830 - val_loss: 1.2857 - val_acc: 0.5453\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 1.3495 - acc: 0.5342 - val_loss: 1.0931 - val_acc: 0.6109\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 1.1992 - acc: 0.5838 - val_loss: 1.1084 - val_acc: 0.6089\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 1.0938 - acc: 0.6301 - val_loss: 0.9045 - val_acc: 0.6792\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.9958 - acc: 0.6676 - val_loss: 0.8750 - val_acc: 0.6954\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 0.9262 - acc: 0.6949 - val_loss: 0.8060 - val_acc: 0.7317\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 13s 502us/step - loss: 0.8476 - acc: 0.7293 - val_loss: 0.6935 - val_acc: 0.7735\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.7923 - acc: 0.7517 - val_loss: 0.6723 - val_acc: 0.7860\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.7253 - acc: 0.7789 - val_loss: 0.6237 - val_acc: 0.7991\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 0.7103 - acc: 0.7870 - val_loss: 0.5809 - val_acc: 0.8191\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 13s 506us/step - loss: 0.6599 - acc: 0.7998 - val_loss: 0.5574 - val_acc: 0.8246\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.6169 - acc: 0.8171 - val_loss: 0.5639 - val_acc: 0.8298\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.5953 - acc: 0.8242 - val_loss: 0.5557 - val_acc: 0.8342\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 0.5602 - acc: 0.8361 - val_loss: 0.5400 - val_acc: 0.8319\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.5348 - acc: 0.8419 - val_loss: 0.5573 - val_acc: 0.8357\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 13s 505us/step - loss: 0.5298 - acc: 0.8478 - val_loss: 0.5153 - val_acc: 0.8400\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.4856 - acc: 0.8598 - val_loss: 0.5264 - val_acc: 0.8557\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.4724 - acc: 0.8633 - val_loss: 0.5676 - val_acc: 0.8333\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 13s 512us/step - loss: 0.4670 - acc: 0.8652 - val_loss: 0.5285 - val_acc: 0.8577\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 13s 514us/step - loss: 0.4430 - acc: 0.8742 - val_loss: 0.5013 - val_acc: 0.8627\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 13s 506us/step - loss: 0.4292 - acc: 0.8760 - val_loss: 0.4932 - val_acc: 0.8577\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.4087 - acc: 0.8831 - val_loss: 0.4937 - val_acc: 0.8615\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.4048 - acc: 0.8827 - val_loss: 0.5177 - val_acc: 0.8598\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.3904 - acc: 0.8878 - val_loss: 0.4925 - val_acc: 0.8650\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 13s 502us/step - loss: 0.3921 - acc: 0.8891 - val_loss: 0.5336 - val_acc: 0.8612\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 0.3834 - acc: 0.8913 - val_loss: 0.5177 - val_acc: 0.8609\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.3655 - acc: 0.8929 - val_loss: 0.4889 - val_acc: 0.8676\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.3529 - acc: 0.8999 - val_loss: 0.5705 - val_acc: 0.8644\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.3417 - acc: 0.9012 - val_loss: 0.5131 - val_acc: 0.8621\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.3364 - acc: 0.9048 - val_loss: 0.5407 - val_acc: 0.8743\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.3255 - acc: 0.9069 - val_loss: 0.5009 - val_acc: 0.8682\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.3127 - acc: 0.9104 - val_loss: 0.5027 - val_acc: 0.8685\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.3228 - acc: 0.9086 - val_loss: 0.5015 - val_acc: 0.8737\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 13s 511us/step - loss: 0.2936 - acc: 0.9135 - val_loss: 0.5498 - val_acc: 0.8807\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 13s 509us/step - loss: 0.2924 - acc: 0.9155 - val_loss: 0.5230 - val_acc: 0.8754\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.2683 - acc: 0.9235 - val_loss: 0.5419 - val_acc: 0.8824\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 13s 507us/step - loss: 0.2750 - acc: 0.9213 - val_loss: 0.5503 - val_acc: 0.8754\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.2784 - acc: 0.9189 - val_loss: 0.5519 - val_acc: 0.8720\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.2701 - acc: 0.9229 - val_loss: 0.6162 - val_acc: 0.8778\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 13s 511us/step - loss: 0.2673 - acc: 0.9227 - val_loss: 0.5860 - val_acc: 0.8714\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 13s 508us/step - loss: 0.2569 - acc: 0.9254 - val_loss: 0.5453 - val_acc: 0.8804\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.2521 - acc: 0.9263 - val_loss: 0.5289 - val_acc: 0.8786\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.2340 - acc: 0.9318 - val_loss: 0.5678 - val_acc: 0.8789\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 13s 510us/step - loss: 0.2212 - acc: 0.9363 - val_loss: 0.5610 - val_acc: 0.8801\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 13s 511us/step - loss: 0.2278 - acc: 0.9334 - val_loss: 0.5297 - val_acc: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fcb032f98>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attRNN.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
