{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Transform Concatenate into 1D drop 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we concatenate the bands of the wt into a 1D vector, we feed this 1D input to the network but we drop the detail band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleSpeechCommands import get_word_dict, read_list, load_data\n",
    "from SimpleSpeechCommands import append_examples,partition_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_label,label_to_word = get_word_dict()\n",
    "path_dataset = '/home/edoardobucheli/TFSpeechCommands/train/audio'\n",
    "#path_dataset = '/Users/edoardobucheli/Documents/MCC/Tesis/Kaggle_SpeechCommands/train/audio'\n",
    "sr = 16000\n",
    "file_length = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = read_list(path_dataset,'training_files.txt')\n",
    "validation_files = read_list(path_dataset,'validation_files.txt')\n",
    "testing_files = read_list(path_dataset,'testing_files.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25112/25112 [00:08<00:00, 3051.85it/s]\n",
      "100%|██████████| 3424/3424 [00:01<00:00, 3032.22it/s]\n",
      "100%|██████████| 3430/3430 [00:01<00:00, 3060.39it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = load_data(training_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_val,y_val = load_data(validation_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_test,y_test = load_data(testing_files,sr,file_length,path_dataset,word_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgrounds = partition_directory(path_dataset,'_background_noise_',sr,file_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = append_examples(x_train,y_train,backgrounds[:300],11)\n",
    "x_val,y_val = append_examples(x_val,y_val,backgrounds[300:320],11)\n",
    "x_test,y_test = append_examples(x_test,y_test,backgrounds[320:],11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 16000)\n",
      "(25412,)\n",
      "(3444, 16000)\n",
      "(3444,)\n",
      "(3508, 16000)\n",
      "(3508,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import wavedec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wavedec(x_train[0],'db4',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = [f for l in test for f in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "8067\n"
     ]
    }
   ],
   "source": [
    "levels = len(test)\n",
    "print(levels)\n",
    "res = len(new_test)-len(test[levels-1])\\\\\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25412/25412 [00:09<00:00, 2687.89it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = np.zeros((len(x_train),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_train)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    #this_plain = []\n",
    "    for j in range(levels-1):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_train_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3444/3444 [00:01<00:00, 2668.74it/s]\n"
     ]
    }
   ],
   "source": [
    "x_val_2 = np.zeros((len(x_val),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_val)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    for j in range(levels-1):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_val_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_length = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities import make_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, _ = x_train_2.shape\n",
    "N_val, _ = x_val_2.shape\n",
    "#N_test, _ = x_test_2.shape\n",
    "\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = make_oh(y_train)\n",
    "y_val_oh = make_oh(y_val)\n",
    "#y_test_oh = make_oh(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 8067)\n",
      "(25412, 12)\n",
      "(3444, 8067)\n",
      "(3444, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_2.shape)\n",
    "print(y_train_oh.shape)\n",
    "print(x_val_2.shape)\n",
    "print(y_val_oh.shape)\n",
    "#print(x_test.shape)\n",
    "#print(y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, CuDNNGRU\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNN1_1D(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8067)              0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 8067, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 8059, 16)          160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1007, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 999, 32)           4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 116, 32)           9248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 19, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 19, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 608)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                38976     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 66,476\n",
      "Trainable params: 66,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "crnn1D = CRNN1_1D(input_shape, n_classes)\n",
    "crnn1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn1D.compile(optimizer = Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 8s 328us/step - loss: 2.2484 - acc: 0.2598 - val_loss: 1.8303 - val_acc: 0.3394\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 6s 254us/step - loss: 1.7521 - acc: 0.3681 - val_loss: 1.4596 - val_acc: 0.4779\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 6s 241us/step - loss: 1.4409 - acc: 0.4890 - val_loss: 1.1977 - val_acc: 0.5694\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 1.2054 - acc: 0.5787 - val_loss: 0.9927 - val_acc: 0.6603\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 6s 237us/step - loss: 1.0702 - acc: 0.6317 - val_loss: 0.8840 - val_acc: 0.6931\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.9632 - acc: 0.6772 - val_loss: 0.8181 - val_acc: 0.7166\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 6s 235us/step - loss: 0.8792 - acc: 0.7037 - val_loss: 0.7960 - val_acc: 0.7262\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 6s 226us/step - loss: 0.8285 - acc: 0.7240 - val_loss: 0.7218 - val_acc: 0.7529\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 6s 229us/step - loss: 0.7903 - acc: 0.7351 - val_loss: 0.7190 - val_acc: 0.7520\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 6s 229us/step - loss: 0.7542 - acc: 0.7491 - val_loss: 0.6730 - val_acc: 0.7683\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.7119 - acc: 0.7639 - val_loss: 0.6627 - val_acc: 0.7741\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 5s 213us/step - loss: 0.6906 - acc: 0.7728 - val_loss: 0.6674 - val_acc: 0.7689\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 5s 214us/step - loss: 0.6661 - acc: 0.7790 - val_loss: 0.6014 - val_acc: 0.7944\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.6346 - acc: 0.7925 - val_loss: 0.5960 - val_acc: 0.7991\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.6034 - acc: 0.8008 - val_loss: 0.5855 - val_acc: 0.8031\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 6s 231us/step - loss: 0.5933 - acc: 0.8065 - val_loss: 0.5900 - val_acc: 0.8089\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.5804 - acc: 0.8077 - val_loss: 0.5662 - val_acc: 0.8133\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 6s 228us/step - loss: 0.5512 - acc: 0.8191 - val_loss: 0.5455 - val_acc: 0.8226\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 6s 232us/step - loss: 0.5367 - acc: 0.8261 - val_loss: 0.5558 - val_acc: 0.8194\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 6s 240us/step - loss: 0.5350 - acc: 0.8228 - val_loss: 0.5342 - val_acc: 0.8264\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 6s 234us/step - loss: 0.5217 - acc: 0.8298 - val_loss: 0.5176 - val_acc: 0.8342\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 6s 231us/step - loss: 0.4977 - acc: 0.8365 - val_loss: 0.5202 - val_acc: 0.8365\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.4790 - acc: 0.8436 - val_loss: 0.5347 - val_acc: 0.8328\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.4800 - acc: 0.8437 - val_loss: 0.5126 - val_acc: 0.8330\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 6s 229us/step - loss: 0.4646 - acc: 0.8469 - val_loss: 0.5136 - val_acc: 0.8391\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 5s 215us/step - loss: 0.4520 - acc: 0.8518 - val_loss: 0.5178 - val_acc: 0.8365\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 6s 253us/step - loss: 0.4478 - acc: 0.8519 - val_loss: 0.5056 - val_acc: 0.8426\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.4386 - acc: 0.8570 - val_loss: 0.5209 - val_acc: 0.8365\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.4358 - acc: 0.8585 - val_loss: 0.5405 - val_acc: 0.8348\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 6s 246us/step - loss: 0.4283 - acc: 0.8612 - val_loss: 0.5254 - val_acc: 0.8359\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 5s 214us/step - loss: 0.4114 - acc: 0.8651 - val_loss: 0.4833 - val_acc: 0.8484\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 6s 235us/step - loss: 0.3977 - acc: 0.8686 - val_loss: 0.5068 - val_acc: 0.8447\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 5s 216us/step - loss: 0.3972 - acc: 0.8695 - val_loss: 0.5043 - val_acc: 0.8429\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 6s 243us/step - loss: 0.3824 - acc: 0.8747 - val_loss: 0.5084 - val_acc: 0.8487\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 6s 223us/step - loss: 0.3699 - acc: 0.8764 - val_loss: 0.5099 - val_acc: 0.8464\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.3675 - acc: 0.8793 - val_loss: 0.4997 - val_acc: 0.8476\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 6s 242us/step - loss: 0.3628 - acc: 0.8813 - val_loss: 0.5060 - val_acc: 0.8487\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 6s 218us/step - loss: 0.3589 - acc: 0.8825 - val_loss: 0.5021 - val_acc: 0.8510\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 6s 227us/step - loss: 0.3556 - acc: 0.8811 - val_loss: 0.4932 - val_acc: 0.8473\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 6s 226us/step - loss: 0.3435 - acc: 0.8860 - val_loss: 0.5129 - val_acc: 0.8508\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 6s 235us/step - loss: 0.3438 - acc: 0.8866 - val_loss: 0.5277 - val_acc: 0.8432\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 6s 240us/step - loss: 0.3296 - acc: 0.8893 - val_loss: 0.5076 - val_acc: 0.8548\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 6s 252us/step - loss: 0.3225 - acc: 0.8925 - val_loss: 0.4937 - val_acc: 0.8545\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 6s 227us/step - loss: 0.3161 - acc: 0.8949 - val_loss: 0.5066 - val_acc: 0.8548\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 6s 240us/step - loss: 0.3165 - acc: 0.8925 - val_loss: 0.5547 - val_acc: 0.8496\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 6s 242us/step - loss: 0.3080 - acc: 0.8967 - val_loss: 0.5043 - val_acc: 0.8528\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3193 - acc: 0.8928 - val_loss: 0.5035 - val_acc: 0.8487\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.2994 - acc: 0.9011 - val_loss: 0.5104 - val_acc: 0.8574\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.2935 - acc: 0.9011 - val_loss: 0.5361 - val_acc: 0.8531\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.2970 - acc: 0.9016 - val_loss: 0.5235 - val_acc: 0.8493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa290c6b908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn1D.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh],\n",
    "           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dropout, Activation\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, Dense, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_v1(input_shape,n_classes):\n",
    "\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(16)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = GlobalMaxPool1D()(X)\n",
    "\n",
    "    X = Dense(64,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "\n",
    "    X = Dense(n_classes,activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input,outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 8067)              0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 8067, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8059, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 8051, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 503, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 503, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 501, 32)           1568      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 499, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 122, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 120, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 28, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 26, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 261,372\n",
      "Trainable params: 261,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1d = conv1d_v1(input_shape,n_classes)\n",
    "cnn1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1d.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 13s 505us/step - loss: 2.2561 - acc: 0.2619 - val_loss: 1.9503 - val_acc: 0.3142\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 1.7173 - acc: 0.3990 - val_loss: 1.4316 - val_acc: 0.5012\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 1.2568 - acc: 0.5694 - val_loss: 1.0513 - val_acc: 0.6333\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 1.0012 - acc: 0.6578 - val_loss: 0.8521 - val_acc: 0.7062\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 11s 424us/step - loss: 0.8373 - acc: 0.7199 - val_loss: 0.7189 - val_acc: 0.7590\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.7259 - acc: 0.7572 - val_loss: 0.6641 - val_acc: 0.7732\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.6434 - acc: 0.7870 - val_loss: 0.5791 - val_acc: 0.8034\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.5953 - acc: 0.8047 - val_loss: 0.5650 - val_acc: 0.8023\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.5507 - acc: 0.8167 - val_loss: 0.5240 - val_acc: 0.8203\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.5104 - acc: 0.8300 - val_loss: 0.5265 - val_acc: 0.8211\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.4797 - acc: 0.8391 - val_loss: 0.4727 - val_acc: 0.8391\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.4579 - acc: 0.8469 - val_loss: 0.4736 - val_acc: 0.8409\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.4270 - acc: 0.8566 - val_loss: 0.4456 - val_acc: 0.8458\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.4040 - acc: 0.8636 - val_loss: 0.4496 - val_acc: 0.8493\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.3917 - acc: 0.8690 - val_loss: 0.4467 - val_acc: 0.8531\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.3808 - acc: 0.8725 - val_loss: 0.4617 - val_acc: 0.8467\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.3654 - acc: 0.8764 - val_loss: 0.4132 - val_acc: 0.8650\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.3472 - acc: 0.8818 - val_loss: 0.4123 - val_acc: 0.8583\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.3344 - acc: 0.8869 - val_loss: 0.4190 - val_acc: 0.8598\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.3338 - acc: 0.8869 - val_loss: 0.4061 - val_acc: 0.8635\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.3067 - acc: 0.8964 - val_loss: 0.3797 - val_acc: 0.8757\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 12s 453us/step - loss: 0.2889 - acc: 0.9025 - val_loss: 0.4349 - val_acc: 0.8537\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 11s 426us/step - loss: 0.2893 - acc: 0.9021 - val_loss: 0.4231 - val_acc: 0.8612\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 11s 419us/step - loss: 0.2750 - acc: 0.9069 - val_loss: 0.3758 - val_acc: 0.8783\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.2816 - acc: 0.9024 - val_loss: 0.4106 - val_acc: 0.8661\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 11s 427us/step - loss: 0.2629 - acc: 0.9130 - val_loss: 0.4393 - val_acc: 0.8641\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 11s 433us/step - loss: 0.2687 - acc: 0.9067 - val_loss: 0.3914 - val_acc: 0.8711\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 11s 438us/step - loss: 0.2484 - acc: 0.9146 - val_loss: 0.4148 - val_acc: 0.8751\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.2456 - acc: 0.9162 - val_loss: 0.4020 - val_acc: 0.8720\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.2392 - acc: 0.9187 - val_loss: 0.4110 - val_acc: 0.8717\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.2360 - acc: 0.9186 - val_loss: 0.4124 - val_acc: 0.8780\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.2160 - acc: 0.9232 - val_loss: 0.4771 - val_acc: 0.8627\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.2181 - acc: 0.9253 - val_loss: 0.3967 - val_acc: 0.8824\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.2128 - acc: 0.9248 - val_loss: 0.4469 - val_acc: 0.8676\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.2085 - acc: 0.9278 - val_loss: 0.4050 - val_acc: 0.8757\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.2099 - acc: 0.9289 - val_loss: 0.4295 - val_acc: 0.8754\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.1911 - acc: 0.9326 - val_loss: 0.4994 - val_acc: 0.8545\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 11s 420us/step - loss: 0.1892 - acc: 0.9337 - val_loss: 0.4496 - val_acc: 0.8688\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1881 - acc: 0.9352 - val_loss: 0.4076 - val_acc: 0.8804\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.1834 - acc: 0.9363 - val_loss: 0.4218 - val_acc: 0.8728\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 11s 423us/step - loss: 0.1713 - acc: 0.9403 - val_loss: 0.4538 - val_acc: 0.8746\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1716 - acc: 0.9402 - val_loss: 0.4371 - val_acc: 0.8731\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.1670 - acc: 0.9431 - val_loss: 0.4355 - val_acc: 0.8804\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1660 - acc: 0.9416 - val_loss: 0.4426 - val_acc: 0.8644\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1578 - acc: 0.9463 - val_loss: 0.4750 - val_acc: 0.8693\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1569 - acc: 0.9444 - val_loss: 0.4395 - val_acc: 0.8810\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.1534 - acc: 0.9473 - val_loss: 0.4413 - val_acc: 0.8740\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 11s 421us/step - loss: 0.1481 - acc: 0.9484 - val_loss: 0.5045 - val_acc: 0.8688\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.1493 - acc: 0.9490 - val_loss: 0.4505 - val_acc: 0.8757\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 11s 422us/step - loss: 0.1469 - acc: 0.9485 - val_loss: 0.4651 - val_acc: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa2885ac978>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1d.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, Dot, Softmax\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, Permute\n",
    "from tensorflow.keras.layers import Bidirectional, CuDNNLSTM, MaxPool1D\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import squeeze,stack, expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttRNNSpeechModelWave(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    #X = Lambda(lambda q: squeeze(q, -1), name='squeeze_last_dim') (X)\n",
    "\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    xFirst = Lambda(lambda q: q[:,16]) (X)\n",
    "    query = Dense(128) (xFirst)\n",
    "    query = Dropout(0.5)(query)\n",
    "\n",
    "    attScores = Dot(axes=[1,2])([query, X])\n",
    "    attScores = Softmax(name='attSoftmax')(attScores)\n",
    "\n",
    "    attVector = Dot(axes=[1,1])([attScores, X])\n",
    "\n",
    "    X = Dense(64, activation = 'relu')(attVector)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(32)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax', name='output')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 8067)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "expand_dims (Lambda)            (None, 8067, 1)      0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 8059, 16)     160         expand_dims[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1007, 16)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 999, 32)      4640        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 124, 32)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 116, 32)      9248        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 19, 32)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 19, 128)      50176       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 19, 128)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 19, 128)      99328       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 19, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 19)           0           dropout_8[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attSoftmax (Softmax)            (None, 19)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 128)          0           attSoftmax[0][0]                 \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 12)           396         dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 190,796\n",
      "Trainable params: 190,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attRNN = AttRNNSpeechModelWave(input_shape,n_classes)\n",
    "attRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attRNN.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 8s 308us/step - loss: 2.3606 - acc: 0.2461 - val_loss: 2.1938 - val_acc: 0.2756\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 2.1463 - acc: 0.2743 - val_loss: 1.9562 - val_acc: 0.2959\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.9628 - acc: 0.2989 - val_loss: 1.7664 - val_acc: 0.3557\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 7s 264us/step - loss: 1.7698 - acc: 0.3596 - val_loss: 1.5308 - val_acc: 0.4640\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.5874 - acc: 0.4363 - val_loss: 1.3283 - val_acc: 0.5418\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.4249 - acc: 0.5040 - val_loss: 1.2091 - val_acc: 0.5836\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.2938 - acc: 0.5630 - val_loss: 1.0677 - val_acc: 0.6301\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.1840 - acc: 0.6120 - val_loss: 0.9717 - val_acc: 0.6777\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 1.0905 - acc: 0.6519 - val_loss: 1.0087 - val_acc: 0.6789\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 7s 274us/step - loss: 0.9950 - acc: 0.6875 - val_loss: 0.8791 - val_acc: 0.7015\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 7s 281us/step - loss: 0.9450 - acc: 0.7063 - val_loss: 0.7752 - val_acc: 0.7462\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 7s 270us/step - loss: 0.8764 - acc: 0.7348 - val_loss: 0.7443 - val_acc: 0.7613\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 7s 271us/step - loss: 0.8125 - acc: 0.7536 - val_loss: 0.7382 - val_acc: 0.7721\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.7591 - acc: 0.7744 - val_loss: 0.6963 - val_acc: 0.7779\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 7s 264us/step - loss: 0.7318 - acc: 0.7884 - val_loss: 0.7626 - val_acc: 0.7666\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.6940 - acc: 0.7971 - val_loss: 0.6739 - val_acc: 0.7965\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 7s 267us/step - loss: 0.6654 - acc: 0.8063 - val_loss: 0.6567 - val_acc: 0.7927\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.6346 - acc: 0.8149 - val_loss: 0.7244 - val_acc: 0.7944\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.6214 - acc: 0.8222 - val_loss: 0.6797 - val_acc: 0.7889\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.5841 - acc: 0.8332 - val_loss: 0.6070 - val_acc: 0.8200\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.5484 - acc: 0.8411 - val_loss: 0.6545 - val_acc: 0.8101\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.5536 - acc: 0.8415 - val_loss: 0.6456 - val_acc: 0.8121\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.5210 - acc: 0.8476 - val_loss: 0.6349 - val_acc: 0.8087\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 7s 264us/step - loss: 0.5237 - acc: 0.8524 - val_loss: 0.6250 - val_acc: 0.8238\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.4938 - acc: 0.8557 - val_loss: 0.6150 - val_acc: 0.8203\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.4793 - acc: 0.8608 - val_loss: 0.5884 - val_acc: 0.8322\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.4513 - acc: 0.8695 - val_loss: 0.5968 - val_acc: 0.8301\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 7s 264us/step - loss: 0.4436 - acc: 0.8722 - val_loss: 0.5939 - val_acc: 0.8284\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.4281 - acc: 0.8759 - val_loss: 0.6002 - val_acc: 0.8403\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.4290 - acc: 0.8728 - val_loss: 0.5700 - val_acc: 0.8362\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.4052 - acc: 0.8842 - val_loss: 0.6628 - val_acc: 0.8342\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.4089 - acc: 0.8821 - val_loss: 0.6007 - val_acc: 0.8389\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 7s 266us/step - loss: 0.3992 - acc: 0.8840 - val_loss: 0.5580 - val_acc: 0.8418\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.3906 - acc: 0.8878 - val_loss: 0.6210 - val_acc: 0.8348\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 7s 265us/step - loss: 0.3630 - acc: 0.8932 - val_loss: 0.5751 - val_acc: 0.8377\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3691 - acc: 0.8923 - val_loss: 0.6229 - val_acc: 0.8502\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 7s 263us/step - loss: 0.3712 - acc: 0.8921 - val_loss: 0.5676 - val_acc: 0.8473\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3534 - acc: 0.8983 - val_loss: 0.6222 - val_acc: 0.8470\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 7s 263us/step - loss: 0.3326 - acc: 0.9013 - val_loss: 0.6358 - val_acc: 0.8432\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3338 - acc: 0.9054 - val_loss: 0.6219 - val_acc: 0.8505\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 7s 263us/step - loss: 0.3128 - acc: 0.9076 - val_loss: 0.6818 - val_acc: 0.8470\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3134 - acc: 0.9092 - val_loss: 0.6741 - val_acc: 0.8496\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3097 - acc: 0.9103 - val_loss: 0.6588 - val_acc: 0.8449\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.3013 - acc: 0.9132 - val_loss: 0.6105 - val_acc: 0.8505\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 7s 263us/step - loss: 0.2992 - acc: 0.9132 - val_loss: 0.6482 - val_acc: 0.8551\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 7s 263us/step - loss: 0.2990 - acc: 0.9114 - val_loss: 0.6676 - val_acc: 0.8455\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.2817 - acc: 0.9188 - val_loss: 0.7342 - val_acc: 0.8467\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.2942 - acc: 0.9133 - val_loss: 0.6710 - val_acc: 0.8589\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 7s 262us/step - loss: 0.2678 - acc: 0.9218 - val_loss: 0.6908 - val_acc: 0.8522\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 7s 261us/step - loss: 0.2536 - acc: 0.9253 - val_loss: 0.9973 - val_acc: 0.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa15d797588>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attRNN.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
