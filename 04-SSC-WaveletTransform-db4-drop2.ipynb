{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Transform Concatenate into 1D drop 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we concatenate the bands of the wt into a 1D vector, we feed this 1D input to the network but we drop two detail bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleSpeechCommands import get_word_dict, read_list, load_data\n",
    "from SimpleSpeechCommands import append_examples,partition_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_label,label_to_word = get_word_dict()\n",
    "path_dataset = '/home/edoardobucheli/TFSpeechCommands/train/audio'\n",
    "#path_dataset = '/Users/edoardobucheli/Documents/MCC/Tesis/Kaggle_SpeechCommands/train/audio'\n",
    "sr = 16000\n",
    "file_length = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = read_list(path_dataset,'training_files.txt')\n",
    "validation_files = read_list(path_dataset,'validation_files.txt')\n",
    "testing_files = read_list(path_dataset,'testing_files.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25112/25112 [00:08<00:00, 3087.27it/s]\n",
      "100%|██████████| 3424/3424 [00:01<00:00, 3135.04it/s]\n",
      "100%|██████████| 3430/3430 [00:01<00:00, 3150.39it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = load_data(training_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_val,y_val = load_data(validation_files,sr,file_length,path_dataset,word_to_label)\n",
    "x_test,y_test = load_data(testing_files,sr,file_length,path_dataset,word_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgrounds = partition_directory(path_dataset,'_background_noise_',sr,file_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = append_examples(x_train,y_train,backgrounds[:300],11)\n",
    "x_val,y_val = append_examples(x_val,y_val,backgrounds[300:320],11)\n",
    "x_test,y_test = append_examples(x_test,y_test,backgrounds[320:],11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 16000)\n",
      "(25412,)\n",
      "(3444, 16000)\n",
      "(3444,)\n",
      "(3508, 16000)\n",
      "(3508,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import wavedec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wavedec(x_train[0],'db4',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = [f for l in test for f in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "4062\n"
     ]
    }
   ],
   "source": [
    "levels = len(test)\n",
    "print(levels)\n",
    "res = len(new_test) - len(test[levels-1]) - len(test[levels-2])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25412/25412 [00:08<00:00, 2884.02it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = np.zeros((len(x_train),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_train)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    #this_plain = []\n",
    "    for j in range(levels-2):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_train_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3444/3444 [00:01<00:00, 2832.17it/s]\n"
     ]
    }
   ],
   "source": [
    "x_val_2 = np.zeros((len(x_val),res))\n",
    "\n",
    "for i, wave in enumerate(tqdm(x_val)):\n",
    "    wt_this =  wavedec(wave,'db4')\n",
    "    end = 0\n",
    "    for j in range(levels-2):\n",
    "        start = end\n",
    "        end += len(wt_this[j])\n",
    "        x_val_2[i,start:end] = wt_this[j]/np.max(np.absolute(wt_this[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_length = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities import make_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, _ = x_train_2.shape\n",
    "N_val, _ = x_val_2.shape\n",
    "#N_test, _ = x_test_2.shape\n",
    "\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = make_oh(y_train)\n",
    "y_val_oh = make_oh(y_val)\n",
    "#y_test_oh = make_oh(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25412, 4062)\n",
      "(25412, 12)\n",
      "(3444, 4062)\n",
      "(3444, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_2.shape)\n",
    "print(y_train_oh.shape)\n",
    "print(x_val_2.shape)\n",
    "print(y_val_oh.shape)\n",
    "#print(x_test.shape)\n",
    "#print(y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, CuDNNGRU\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNN1_1D(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = CuDNNGRU(32, return_sequences = True)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4062)              0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 4062, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 4054, 16)          160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 506, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 498, 32)           4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 54, 32)            9248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 9, 32)             6336      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 9, 32)             6336      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 45,996\n",
      "Trainable params: 45,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "crnn1D = CRNN1_1D(input_shape, n_classes)\n",
    "crnn1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn1D.compile(optimizer = Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 5s 182us/step - loss: 2.2694 - acc: 0.2585 - val_loss: 1.9789 - val_acc: 0.2997\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 3s 117us/step - loss: 1.8036 - acc: 0.3542 - val_loss: 1.4825 - val_acc: 0.4515\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 3s 117us/step - loss: 1.5026 - acc: 0.4597 - val_loss: 1.2920 - val_acc: 0.5363\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 3s 130us/step - loss: 1.2974 - acc: 0.5453 - val_loss: 1.1098 - val_acc: 0.6141\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 3s 119us/step - loss: 1.1414 - acc: 0.6053 - val_loss: 0.9658 - val_acc: 0.6585\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 3s 123us/step - loss: 1.0438 - acc: 0.6438 - val_loss: 0.8944 - val_acc: 0.6908\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.9725 - acc: 0.6724 - val_loss: 0.8490 - val_acc: 0.7088\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 3s 121us/step - loss: 0.9229 - acc: 0.6883 - val_loss: 0.8040 - val_acc: 0.7259\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 3s 119us/step - loss: 0.8728 - acc: 0.7090 - val_loss: 0.7790 - val_acc: 0.7314\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.8399 - acc: 0.7215 - val_loss: 0.7661 - val_acc: 0.7395\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.8016 - acc: 0.7343 - val_loss: 0.7429 - val_acc: 0.7546\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 3s 123us/step - loss: 0.7784 - acc: 0.7459 - val_loss: 0.7185 - val_acc: 0.7610\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.7405 - acc: 0.7558 - val_loss: 0.6915 - val_acc: 0.7645\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.7262 - acc: 0.7607 - val_loss: 0.6789 - val_acc: 0.7706\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 3s 119us/step - loss: 0.7012 - acc: 0.7713 - val_loss: 0.6827 - val_acc: 0.7729\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.6871 - acc: 0.7746 - val_loss: 0.6572 - val_acc: 0.7721\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.6713 - acc: 0.7827 - val_loss: 0.6535 - val_acc: 0.7825\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 3s 115us/step - loss: 0.6516 - acc: 0.7890 - val_loss: 0.6402 - val_acc: 0.7828\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 3s 116us/step - loss: 0.6337 - acc: 0.7948 - val_loss: 0.6426 - val_acc: 0.7840\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.6228 - acc: 0.7982 - val_loss: 0.6295 - val_acc: 0.7846\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.6003 - acc: 0.8007 - val_loss: 0.6399 - val_acc: 0.7857\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 3s 117us/step - loss: 0.5925 - acc: 0.8052 - val_loss: 0.6309 - val_acc: 0.7886\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 3s 124us/step - loss: 0.5831 - acc: 0.8102 - val_loss: 0.6255 - val_acc: 0.7912\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.5707 - acc: 0.8149 - val_loss: 0.6233 - val_acc: 0.7921\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 3s 121us/step - loss: 0.5578 - acc: 0.8178 - val_loss: 0.6145 - val_acc: 0.7953\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.5395 - acc: 0.8233 - val_loss: 0.6581 - val_acc: 0.7866\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 3s 119us/step - loss: 0.5291 - acc: 0.8281 - val_loss: 0.6242 - val_acc: 0.7944\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.5264 - acc: 0.8289 - val_loss: 0.6456 - val_acc: 0.7898\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 3s 123us/step - loss: 0.5128 - acc: 0.8340 - val_loss: 0.6136 - val_acc: 0.8011\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 3s 121us/step - loss: 0.4902 - acc: 0.8412 - val_loss: 0.6107 - val_acc: 0.8017\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4882 - acc: 0.8409 - val_loss: 0.6275 - val_acc: 0.8040\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 3s 123us/step - loss: 0.4763 - acc: 0.8448 - val_loss: 0.6222 - val_acc: 0.8069\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 3s 119us/step - loss: 0.4747 - acc: 0.8420 - val_loss: 0.6138 - val_acc: 0.8037\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.4643 - acc: 0.8499 - val_loss: 0.6451 - val_acc: 0.7976\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4610 - acc: 0.8517 - val_loss: 0.6118 - val_acc: 0.8026\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.4498 - acc: 0.8536 - val_loss: 0.6149 - val_acc: 0.8063\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4406 - acc: 0.8548 - val_loss: 0.6239 - val_acc: 0.7985\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4312 - acc: 0.8615 - val_loss: 0.6377 - val_acc: 0.7988\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.4284 - acc: 0.8592 - val_loss: 0.6180 - val_acc: 0.8092\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 3s 124us/step - loss: 0.4164 - acc: 0.8629 - val_loss: 0.6255 - val_acc: 0.8078\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4138 - acc: 0.8647 - val_loss: 0.6180 - val_acc: 0.8089\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.4101 - acc: 0.8663 - val_loss: 0.6518 - val_acc: 0.7999\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 3s 120us/step - loss: 0.3989 - acc: 0.8682 - val_loss: 0.6380 - val_acc: 0.8116\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 3s 125us/step - loss: 0.3896 - acc: 0.8728 - val_loss: 0.6635 - val_acc: 0.8078\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 3s 125us/step - loss: 0.3763 - acc: 0.8757 - val_loss: 0.6363 - val_acc: 0.8052\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.3764 - acc: 0.8777 - val_loss: 0.6495 - val_acc: 0.8052\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 3s 125us/step - loss: 0.3632 - acc: 0.8810 - val_loss: 0.6739 - val_acc: 0.8095\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 3s 118us/step - loss: 0.3675 - acc: 0.8790 - val_loss: 0.6626 - val_acc: 0.8084\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.3665 - acc: 0.8813 - val_loss: 0.6855 - val_acc: 0.8101\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 3s 122us/step - loss: 0.3714 - acc: 0.8771 - val_loss: 0.6571 - val_acc: 0.8101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f26396ff588>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn1D.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh],\n",
    "           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dropout, Activation\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, Dense, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_v1(input_shape,n_classes):\n",
    "\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(16,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(16)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(32,3,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(4)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = Conv1D(256,3,activation='relu',padding='valid')(X)\n",
    "    X = GlobalMaxPool1D()(X)\n",
    "\n",
    "    X = Dense(64,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "\n",
    "    X = Dense(n_classes,activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input,outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4062)              0         \n",
      "_________________________________________________________________\n",
      "expand_dims (Lambda)         (None, 4062, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4054, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 4046, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 252, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 252, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 250, 32)           1568      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 248, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 60, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 58, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 12, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 10, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 261,372\n",
      "Trainable params: 261,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1d = conv1d_v1(input_shape,n_classes)\n",
    "cnn1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1d.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 8s 297us/step - loss: 2.2452 - acc: 0.2641 - val_loss: 1.9435 - val_acc: 0.3165\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 6s 235us/step - loss: 1.6892 - acc: 0.3932 - val_loss: 1.4206 - val_acc: 0.5038\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 1.2580 - acc: 0.5571 - val_loss: 1.1545 - val_acc: 0.5830\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 6s 226us/step - loss: 1.0257 - acc: 0.6402 - val_loss: 0.9077 - val_acc: 0.6847\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 6s 227us/step - loss: 0.8641 - acc: 0.6979 - val_loss: 0.8059 - val_acc: 0.7178\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 6s 219us/step - loss: 0.7645 - acc: 0.7358 - val_loss: 0.7413 - val_acc: 0.7451\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 6s 219us/step - loss: 0.6981 - acc: 0.7643 - val_loss: 0.6965 - val_acc: 0.7605\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.6479 - acc: 0.7774 - val_loss: 0.6588 - val_acc: 0.7790\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.6075 - acc: 0.7907 - val_loss: 0.6587 - val_acc: 0.7744\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.5764 - acc: 0.8038 - val_loss: 0.7067 - val_acc: 0.7573\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.5502 - acc: 0.8129 - val_loss: 0.7034 - val_acc: 0.7642\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.5181 - acc: 0.8232 - val_loss: 0.5539 - val_acc: 0.8069\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.4941 - acc: 0.8306 - val_loss: 0.5699 - val_acc: 0.7956\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 6s 220us/step - loss: 0.4707 - acc: 0.8415 - val_loss: 0.5197 - val_acc: 0.8278\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.4540 - acc: 0.8427 - val_loss: 0.5167 - val_acc: 0.8194\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.4513 - acc: 0.8459 - val_loss: 0.5296 - val_acc: 0.8177\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.4255 - acc: 0.8539 - val_loss: 0.5114 - val_acc: 0.8226\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.4044 - acc: 0.8624 - val_loss: 0.4960 - val_acc: 0.8359\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3979 - acc: 0.8633 - val_loss: 0.4886 - val_acc: 0.8351\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3881 - acc: 0.8651 - val_loss: 0.4697 - val_acc: 0.8415\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.3622 - acc: 0.8772 - val_loss: 0.4955 - val_acc: 0.8322\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3564 - acc: 0.8782 - val_loss: 0.5348 - val_acc: 0.8220\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3441 - acc: 0.8827 - val_loss: 0.4652 - val_acc: 0.8418\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3247 - acc: 0.8882 - val_loss: 0.4968 - val_acc: 0.8374\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.3279 - acc: 0.8856 - val_loss: 0.5069 - val_acc: 0.8432\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.3146 - acc: 0.8911 - val_loss: 0.4773 - val_acc: 0.8391\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.3129 - acc: 0.8914 - val_loss: 0.4844 - val_acc: 0.8420\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2928 - acc: 0.8998 - val_loss: 0.4898 - val_acc: 0.8420\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.2853 - acc: 0.9010 - val_loss: 0.4752 - val_acc: 0.8467\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2828 - acc: 0.9025 - val_loss: 0.4431 - val_acc: 0.8499\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2755 - acc: 0.9055 - val_loss: 0.4924 - val_acc: 0.8426\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2757 - acc: 0.9047 - val_loss: 0.4878 - val_acc: 0.8400\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2646 - acc: 0.9075 - val_loss: 0.4705 - val_acc: 0.8499\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2551 - acc: 0.9127 - val_loss: 0.4557 - val_acc: 0.8548\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2420 - acc: 0.9168 - val_loss: 0.4534 - val_acc: 0.8479\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.2522 - acc: 0.9124 - val_loss: 0.5051 - val_acc: 0.8339\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.2446 - acc: 0.9135 - val_loss: 0.4813 - val_acc: 0.8505\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2272 - acc: 0.9221 - val_loss: 0.4798 - val_acc: 0.8534\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 6s 225us/step - loss: 0.2393 - acc: 0.9170 - val_loss: 0.5080 - val_acc: 0.8406\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.2199 - acc: 0.9227 - val_loss: 0.4762 - val_acc: 0.8554\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 6s 224us/step - loss: 0.2130 - acc: 0.9239 - val_loss: 0.4888 - val_acc: 0.8447\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2101 - acc: 0.9265 - val_loss: 0.4829 - val_acc: 0.8505\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.2033 - acc: 0.9291 - val_loss: 0.4996 - val_acc: 0.8516\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.2013 - acc: 0.9303 - val_loss: 0.5176 - val_acc: 0.8464\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.1958 - acc: 0.9311 - val_loss: 0.4945 - val_acc: 0.8566\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 6s 221us/step - loss: 0.1821 - acc: 0.9366 - val_loss: 0.5205 - val_acc: 0.8508\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.1891 - acc: 0.9339 - val_loss: 0.5240 - val_acc: 0.8449\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.1858 - acc: 0.9343 - val_loss: 0.5102 - val_acc: 0.8473\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.1758 - acc: 0.9394 - val_loss: 0.5152 - val_acc: 0.8441\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 6s 222us/step - loss: 0.1726 - acc: 0.9394 - val_loss: 0.5199 - val_acc: 0.8476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f26341d8898>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1d.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, Dot, Softmax\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, Permute\n",
    "from tensorflow.keras.layers import Bidirectional, CuDNNLSTM, MaxPool1D\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import squeeze,stack, expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttRNNSpeechModelWave(input_shape, n_classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Lambda(lambda q: expand_dims(q, -1), name='expand_dims') (X_input)\n",
    "\n",
    "    X = Conv1D(16,9, activation='relu', padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(8)(X)\n",
    "\n",
    "    X = Conv1D(32,9,activation='relu',padding='valid')(X)\n",
    "    X = MaxPool1D(6)(X)\n",
    "\n",
    "    #X = Lambda(lambda q: squeeze(q, -1), name='squeeze_last_dim') (X)\n",
    "\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(CuDNNLSTM(64, return_sequences = True)) (X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    xFirst = Lambda(lambda q: q[:,5]) (X)\n",
    "    query = Dense(128) (xFirst)\n",
    "    query = Dropout(0.5)(query)\n",
    "\n",
    "    attScores = Dot(axes=[1,2])([query, X])\n",
    "    attScores = Softmax(name='attSoftmax')(attScores)\n",
    "\n",
    "    attVector = Dot(axes=[1,1])([attScores, X])\n",
    "\n",
    "    X = Dense(64, activation = 'relu')(attVector)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(32)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(n_classes, activation = 'softmax', name='output')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (file_length,)\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 4062)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "expand_dims (Lambda)            (None, 4062, 1)      0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 4054, 16)     160         expand_dims[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 506, 16)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 498, 32)      4640        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 62, 32)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 54, 32)       9248        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 9, 32)        0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 9, 128)       50176       max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 9, 128)       0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 9, 128)       99328       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 9, 128)       0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128)          0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 9)            0           dropout_12[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attSoftmax (Softmax)            (None, 9)            0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 128)          0           attSoftmax[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 12)           396         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 190,796\n",
      "Trainable params: 190,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attRNN = AttRNNSpeechModelWave(input_shape,n_classes)\n",
    "attRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "attRNN.compile(optimizer=Adam(lr),loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25412 samples, validate on 3444 samples\n",
      "Epoch 1/50\n",
      "25412/25412 [==============================] - 5s 197us/step - loss: 2.3302 - acc: 0.2459 - val_loss: 2.1898 - val_acc: 0.2526\n",
      "Epoch 2/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 2.1236 - acc: 0.2627 - val_loss: 1.9468 - val_acc: 0.2970\n",
      "Epoch 3/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 1.8430 - acc: 0.3338 - val_loss: 1.4352 - val_acc: 0.5012\n",
      "Epoch 4/50\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 1.5130 - acc: 0.4651 - val_loss: 1.2661 - val_acc: 0.5534\n",
      "Epoch 5/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 1.3463 - acc: 0.5372 - val_loss: 1.1042 - val_acc: 0.6150\n",
      "Epoch 6/50\n",
      "25412/25412 [==============================] - 4s 153us/step - loss: 1.2273 - acc: 0.5842 - val_loss: 1.0600 - val_acc: 0.6417\n",
      "Epoch 7/50\n",
      "25412/25412 [==============================] - 4s 145us/step - loss: 1.1433 - acc: 0.6171 - val_loss: 1.0024 - val_acc: 0.6626\n",
      "Epoch 8/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 1.0787 - acc: 0.6458 - val_loss: 0.9079 - val_acc: 0.6943\n",
      "Epoch 9/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 1.0239 - acc: 0.6700 - val_loss: 0.8750 - val_acc: 0.6974\n",
      "Epoch 10/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 0.9587 - acc: 0.6936 - val_loss: 0.8508 - val_acc: 0.7154\n",
      "Epoch 11/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.9097 - acc: 0.7130 - val_loss: 0.7920 - val_acc: 0.7390\n",
      "Epoch 12/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.8817 - acc: 0.7285 - val_loss: 0.8368 - val_acc: 0.7233\n",
      "Epoch 13/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.8312 - acc: 0.7464 - val_loss: 0.7800 - val_acc: 0.7448\n",
      "Epoch 14/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.8146 - acc: 0.7517 - val_loss: 0.7431 - val_acc: 0.7651\n",
      "Epoch 15/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 0.7682 - acc: 0.7655 - val_loss: 0.7333 - val_acc: 0.7622\n",
      "Epoch 16/50\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 0.7560 - acc: 0.7734 - val_loss: 0.7141 - val_acc: 0.7776\n",
      "Epoch 17/50\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7332 - acc: 0.7826 - val_loss: 0.7446 - val_acc: 0.7631\n",
      "Epoch 18/50\n",
      "25412/25412 [==============================] - 5s 186us/step - loss: 0.7001 - acc: 0.7925 - val_loss: 0.7166 - val_acc: 0.7811\n",
      "Epoch 19/50\n",
      "25412/25412 [==============================] - 5s 187us/step - loss: 0.6749 - acc: 0.8007 - val_loss: 0.7962 - val_acc: 0.7642\n",
      "Epoch 20/50\n",
      "25412/25412 [==============================] - 5s 181us/step - loss: 0.6603 - acc: 0.8049 - val_loss: 0.6827 - val_acc: 0.7947\n",
      "Epoch 21/50\n",
      "25412/25412 [==============================] - 5s 201us/step - loss: 0.6421 - acc: 0.8102 - val_loss: 0.6888 - val_acc: 0.7843\n",
      "Epoch 22/50\n",
      "25412/25412 [==============================] - 5s 198us/step - loss: 0.6173 - acc: 0.8205 - val_loss: 0.6983 - val_acc: 0.7938\n",
      "Epoch 23/50\n",
      "25412/25412 [==============================] - 5s 198us/step - loss: 0.6183 - acc: 0.8209 - val_loss: 0.6689 - val_acc: 0.7999\n",
      "Epoch 24/50\n",
      "25412/25412 [==============================] - 5s 188us/step - loss: 0.5908 - acc: 0.8277 - val_loss: 0.6531 - val_acc: 0.7970\n",
      "Epoch 25/50\n",
      "25412/25412 [==============================] - 5s 199us/step - loss: 0.5711 - acc: 0.8339 - val_loss: 0.7004 - val_acc: 0.7901\n",
      "Epoch 26/50\n",
      "25412/25412 [==============================] - 4s 166us/step - loss: 0.5807 - acc: 0.8319 - val_loss: 0.6401 - val_acc: 0.8060\n",
      "Epoch 27/50\n",
      "25412/25412 [==============================] - 5s 184us/step - loss: 0.5551 - acc: 0.8374 - val_loss: 0.6644 - val_acc: 0.8107\n",
      "Epoch 28/50\n",
      "25412/25412 [==============================] - 4s 148us/step - loss: 0.5548 - acc: 0.8377 - val_loss: 0.6430 - val_acc: 0.8063\n",
      "Epoch 29/50\n",
      "25412/25412 [==============================] - 4s 175us/step - loss: 0.5278 - acc: 0.8444 - val_loss: 0.6877 - val_acc: 0.8118\n",
      "Epoch 30/50\n",
      "25412/25412 [==============================] - 4s 168us/step - loss: 0.5108 - acc: 0.8513 - val_loss: 0.7209 - val_acc: 0.8101\n",
      "Epoch 31/50\n",
      "25412/25412 [==============================] - 5s 187us/step - loss: 0.5264 - acc: 0.8477 - val_loss: 0.6663 - val_acc: 0.8092\n",
      "Epoch 32/50\n",
      "25412/25412 [==============================] - 4s 171us/step - loss: 0.4853 - acc: 0.8597 - val_loss: 0.6815 - val_acc: 0.8165\n",
      "Epoch 33/50\n",
      "25412/25412 [==============================] - 4s 162us/step - loss: 0.4967 - acc: 0.8562 - val_loss: 0.6626 - val_acc: 0.8240\n",
      "Epoch 34/50\n",
      "25412/25412 [==============================] - 5s 178us/step - loss: 0.4787 - acc: 0.8621 - val_loss: 0.6639 - val_acc: 0.8246\n",
      "Epoch 35/50\n",
      "25412/25412 [==============================] - 5s 187us/step - loss: 0.4664 - acc: 0.8629 - val_loss: 0.6812 - val_acc: 0.8089\n",
      "Epoch 36/50\n",
      "25412/25412 [==============================] - 4s 176us/step - loss: 0.4711 - acc: 0.8641 - val_loss: 0.6966 - val_acc: 0.8191\n",
      "Epoch 37/50\n",
      "25412/25412 [==============================] - 4s 165us/step - loss: 0.4543 - acc: 0.8713 - val_loss: 0.6908 - val_acc: 0.8104\n",
      "Epoch 38/50\n",
      "25412/25412 [==============================] - 4s 172us/step - loss: 0.4366 - acc: 0.8763 - val_loss: 0.6673 - val_acc: 0.8232\n",
      "Epoch 39/50\n",
      "25412/25412 [==============================] - 4s 165us/step - loss: 0.4255 - acc: 0.8780 - val_loss: 0.7268 - val_acc: 0.8182\n",
      "Epoch 40/50\n",
      "25412/25412 [==============================] - 4s 177us/step - loss: 0.4253 - acc: 0.8775 - val_loss: 0.7307 - val_acc: 0.8156\n",
      "Epoch 41/50\n",
      "25412/25412 [==============================] - 5s 179us/step - loss: 0.4425 - acc: 0.8722 - val_loss: 0.7000 - val_acc: 0.8281\n",
      "Epoch 42/50\n",
      "25412/25412 [==============================] - 5s 187us/step - loss: 0.4084 - acc: 0.8825 - val_loss: 0.6539 - val_acc: 0.8310\n",
      "Epoch 43/50\n",
      "25412/25412 [==============================] - 4s 170us/step - loss: 0.4035 - acc: 0.8833 - val_loss: 0.6961 - val_acc: 0.8258\n",
      "Epoch 44/50\n",
      "25412/25412 [==============================] - 5s 183us/step - loss: 0.3903 - acc: 0.8869 - val_loss: 0.7440 - val_acc: 0.8275\n",
      "Epoch 45/50\n",
      "25412/25412 [==============================] - 4s 167us/step - loss: 0.3790 - acc: 0.8895 - val_loss: 0.8466 - val_acc: 0.8095\n",
      "Epoch 46/50\n",
      "25412/25412 [==============================] - 4s 177us/step - loss: 0.3893 - acc: 0.8865 - val_loss: 0.7431 - val_acc: 0.8272\n",
      "Epoch 47/50\n",
      "25412/25412 [==============================] - 4s 148us/step - loss: 0.3898 - acc: 0.8874 - val_loss: 0.6835 - val_acc: 0.8272\n",
      "Epoch 48/50\n",
      "25412/25412 [==============================] - 4s 144us/step - loss: 0.3542 - acc: 0.8975 - val_loss: 0.6958 - val_acc: 0.8229\n",
      "Epoch 49/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.3572 - acc: 0.8956 - val_loss: 0.7402 - val_acc: 0.8351\n",
      "Epoch 50/50\n",
      "25412/25412 [==============================] - 4s 143us/step - loss: 0.3729 - acc: 0.8935 - val_loss: 0.6962 - val_acc: 0.8301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2508b31fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attRNN.fit(x_train_2,y_train_oh,\n",
    "           batch_size=256, epochs = 50,\n",
    "           validation_data=[x_val_2,y_val_oh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
